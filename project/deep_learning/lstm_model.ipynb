{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Recurrent, BatchNormalization, LSTM\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "MODEL_DIR = './../trained_models/lstm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_samples(x, y, n=10):\n",
    "    higher = len(x)\n",
    "    print(higher)\n",
    "    for i in range(n):\n",
    "        j = np.random.randint(0, higher)\n",
    "        print(x[j], y[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data[:2]\n",
    "        self.net_params = test_data[2:]\n",
    "        self.epochs = [16, 32, 64, 128]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch in self.epochs:\n",
    "            x, y = self.test_data\n",
    "            h_l, n, t = self.net_params\n",
    "            loss, acc = self.model.evaluate(x.reshape(len(x), 1,10), y, verbose=0)\n",
    "            with open('arch_cmp.txt', 'a+') as f:\n",
    "                f.write('layers: {:}, neurons: {:}, epoch:  {:}, loss: {}, acc: {}\\n'.format(h_l, n, epoch, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio=0.2):\n",
    "    # converting to numpy array\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # splitting dataset in training and testing\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = ratio)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def build_model(x_train, y_train, x_test, y_test, target, hidden_layers=2, neurons=32, epochs=10, plot=True, \n",
    "                model_path=None, arch_test=False):\n",
    "\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(64, input_shape = (1, 10)))\n",
    "    # normalizing the input\n",
    "    model.add(BatchNormalization(input_shape=(1,10)))\n",
    "    \n",
    "    for i in range(hidden_layers - 1):\n",
    "        model.add(LSTM(neurons, dropout=0.3, recurrent_dropout=0.2, return_sequences = True))\n",
    "    model.add(LSTM(neurons, dropout=0.3, recurrent_dropout=0.2))\n",
    "    \n",
    "    model.add(Dense(10, activation='sigmoid', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "    # default batch size = 32\n",
    "    t0 = time.time()\n",
    "    \n",
    "    if arch_test:\n",
    "        history = model.fit(x_train.reshape(len(x_train),1,10), y_train, validation_split=0.15, epochs=epochs, verbose=0, \n",
    "                        callbacks=[TestCallback((x_test, y_test, hidden_layers, neurons, target))]) \n",
    "    else:\n",
    "        history = model.fit(x_train.reshape(len(x_train),1,10), y_train, validation_split=0.15, epochs=epochs, verbose=0) \n",
    "\n",
    "    t1 = time.time()\n",
    "    \n",
    "    if model_path:\n",
    "        model.save(model_path)\n",
    "        \n",
    "    if plot:\n",
    "        #print(history.history.keys())\n",
    "        os.makedirs('plots_final/{:}'.format(target), exist_ok=True)\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        #  \"Accuracy\"\n",
    "        plt.subplot(121)\n",
    "        plt.plot(history.history['categorical_accuracy'])\n",
    "        plt.plot(history.history['val_categorical_accuracy'])\n",
    "        plt.grid()\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['Training data', 'Validation data'], loc='lower right')\n",
    "        # \"Loss\"\n",
    "        plt.subplot(122)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.grid()\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['Training data', 'Validation data'], loc='upper right')\n",
    "        plt.savefig('plots_final/{:}/plot_{:}_{:}_{:}.pdf'.format(target, hidden_layers, neurons, epochs))\n",
    "        plt.close()\n",
    "        \n",
    "    loss, acc = model.evaluate(x_test.reshape(len(x_test), 1,10), y_test, verbose=0)\n",
    "    if arch_test:\n",
    "        with open('arch_cmp.txt', 'a+') as f:\n",
    "            f.write('layers: {:}, neurons: {:}, epoch:  {:}, loss: {}, acc: {}, time: {}\\n'.format(hidden_layers, neurons, epochs, \n",
    "                                                                                     loss, acc, t1-t0))\n",
    "    \n",
    "    return history.history, [loss, acc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = 4\n",
    "neurons = 32\n",
    "train_epochs = 150\n",
    "\n",
    "for target in os.listdir(MODEL_DIR):\n",
    "    path = os.path.join(MODEL_DIR, target)\n",
    "    print(target)  with open(os.path.join(path, 'train_hist.pkl'), 'wb') as th:\n",
    "        pickle.dump(train_hist, th)\n",
    "        \n",
    "    with open(os.path.join(path, 'test_metrics.pkl'), 'wb') as tm:\n",
    "        pickle.dump(test_metrics, tm)\n",
    "    train_hist = []\n",
    "    test_metrics = []\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for dataset in os.listdir(path):\n",
    "        file = os.path.join(path, dataset)\n",
    "        with open(file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:    \n",
    "                cnt, label = line.split(',')\n",
    "                cnt = np.array([int(c) for c in cnt.split()[1:]], dtype=np.int)\n",
    "                label = np.array([int(l) for l in label.split()], dtype=np.int)\n",
    "                x.append(cnt)\n",
    "                y.append(label)\n",
    "        \n",
    "    x_t, y_t, x_ts, y_ts = split_data(x, y)\n",
    "    h, m = build_model(x_t, y_t, x_ts, y_ts, target, neurons=neurons, hidden_layers=layers, epochs=train_epochs,\n",
    "                           plot=False, model_path=os.path.join(model,'{:}_model.h5'.format(router)), arch_test=True)\n",
    "    print(model, m)\n",
    "    train_hist.append(h)\n",
    "    test_metrics.append(m)\n",
    "     \n",
    "        \n",
    "    with open(os.path.join(path, 'train_hist.pkl'), 'wb') as th:\n",
    "        pickle.dump(train_hist, th)\n",
    "        \n",
    "    with open(os.path.join(path, 'test_metrics.pkl'), 'wb') as tm:\n",
    "        pickle.dump(test_metrics, tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1_172_168_3_2\n",
      "Run 1\n",
      "Run 1\n"
     ]
    }
   ],
   "source": [
    "#CELL FOR ARCHITECTURE TESTING\n",
    "\n",
    "layers = [2, 4, 6, 8]\n",
    "neurons = [4, 8, 16, 32, 64, 128]\n",
    "epochs = [16, 32, 64, 128]\n",
    "train_epochs = 150\n",
    "train_hist = {}\n",
    "test_metrics = {}\n",
    "\n",
    "architecture_results = {}\n",
    "architecture_history = {}\n",
    "\n",
    "for target in os.listdir(MODEL_DIR):\n",
    "    path = os.path.join(MODEL_DIR, target)\n",
    "    if target != 'r1_172_168_3_2':\n",
    "        continue\n",
    "    print(target)\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for dataset in os.listdir(path):\n",
    "        file = os.path.join(path, dataset)\n",
    "        with open(file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:    \n",
    "                cnt, label = line.split(',')\n",
    "                cnt = np.array([int(c) for c in cnt.split()[1:]], dtype=np.int)\n",
    "                label = np.array([int(l) for l in label.split()], dtype=np.int)\n",
    "                x.append(cnt)\n",
    "                y.append(label)\n",
    "        \n",
    "    # running 10 times to find the best architecture\n",
    "    for k in range(10):\n",
    "        print('Run 1')\n",
    "        x_t, y_t, x_ts, y_ts = split_data(x, y)\n",
    "\n",
    "        for layer in layers:\n",
    "            for neuron in neurons:\n",
    "                h, m = build_model(x_t, y_t, x_ts, y_ts, target, neurons=neuron, hidden_layers=layer, epochs=train_epochs, \n",
    "                                   plot=False, arch_test=True)\n",
    "                key = '{:}_{:}'.format(layer, neuron)\n",
    "                if key not in architecture_results:\n",
    "                    architecture_results[key] = []\n",
    "                    architecture_history[key] = []\n",
    "                \n",
    "                architecture_results[key].append(m)\n",
    "                architecture_history[key].append(h)\n",
    "        \n",
    "    with open('arch_hist.pkl', 'wb') as ah:\n",
    "        pickle.dump(architecture_history, ah)\n",
    "        \n",
    "    with open('arch_metrics.pkl', 'wb') as am:\n",
    "        pickle.dump(architecture_results, am)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
