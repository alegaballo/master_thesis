{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib64/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.20) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/usr/lib64/python3.6/site-packages/matplotlib/font_manager.py:280: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Recurrent, BatchNormalization, LSTM\n",
    "from keras.regularizers import l2\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "MODEL_DIR = './project/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_samples(x, y, n=10):\n",
    "    higher = len(x)\n",
    "    print(higher)\n",
    "    for i in range(n):\n",
    "        j = np.random.randint(0, higher)\n",
    "        print(x[j], y[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio=0.2):\n",
    "    # converting to numpy array\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # splitting dataset in training and testing\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = ratio)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def build_model(x_train, y_train, x_test, y_test, target, hidden_layers=2, neurons=32, epochs=10, plot=True):\n",
    "\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(64, input_shape = (1, 10)))\n",
    "    # normalizing the input\n",
    "    model.add(BatchNormalization(input_shape=(1,10)))\n",
    "    \n",
    "    for i in range(hidden_layers - 1):\n",
    "        model.add(LSTM(neurons, dropout=0.3, recurrent_dropout=0.2, return_sequences = True))\n",
    "    model.add(LSTM(neurons, dropout=0.3, recurrent_dropout=0.2))\n",
    "    \n",
    "    model.add(Dense(10, activation='sigmoid', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "    metrics=['categorical_accuracy'])\n",
    "\n",
    "    # default batch size = 32\n",
    "    t0 = time.time()\n",
    "    history = model.fit(x_train.reshape(len(x_train),1,10), y_train, validation_split=0.15, epochs=epochs, verbose=0) \n",
    "    t1 = time.time()\n",
    "    if plot:\n",
    "        #print(history.history.keys())\n",
    "        os.makedirs('plots/{:}'.format(target), exist_ok=True)\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        #  \"Accuracy\"\n",
    "        plt.subplot(121)\n",
    "        plt.plot(history.history['categorical_accuracy'])\n",
    "        plt.plot(history.history['val_categorical_accuracy'])\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['Training data', 'Validation data'], loc='upper left')\n",
    "        # \"Loss\"\n",
    "        plt.subplot(122)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['Training data', 'Validation data'], loc='upper left')\n",
    "        plt.savefig('plots/{:}/plot_{:}_{:}_{:}.pdf'.format(target, hidden_layers, neurons, epochs))\n",
    "        plt.close()\n",
    "#         plt.show()\n",
    "        \n",
    "#     print('Evaluating model')\n",
    "    metrics = model.evaluate(x_test.reshape(len(x_test), 1,10), y_test, verbose=0)\n",
    "#     print('\\n')\n",
    "    with open('./model_cmp_time_norm.txt', 'a+') as model_f:\n",
    "        model_f.write('hidden layers: {:}, neurons: {:}, epochs: {:}, time: {:}'\n",
    "                .format(hidden_layers, neurons, epochs, t1-t0))\n",
    "        for i in range(len(model.metrics_names)):\n",
    "            model_f.write(\" \" + str(model.metrics_names[i]) + \": \" + str(metrics[i]))\n",
    "        model_f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_172_168_4_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "layers = [8]\n",
    "neurons = [4, 8, 16, 32, 64, 128]\n",
    "epochs = [16, 32, 64, 128]\n",
    "\n",
    "for target in os.listdir(MODEL_DIR):\n",
    "    path = os.path.join(MODEL_DIR, target)\n",
    "    if target!='r2_172_168_4_2':\n",
    "        continue\n",
    "        \n",
    "    print(target)\n",
    "    for router in os.listdir(path):\n",
    "        model = os.path.join(path, router)\n",
    "        x = []\n",
    "        y = []\n",
    "        for dataset in os.listdir(model):\n",
    "            file = os.path.join(model, dataset)\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            for line in lines:    \n",
    "                cnt, label = line.split(',')\n",
    "                cnt = np.array([int(c) for c in cnt.split()[1:]], dtype=np.int)\n",
    "                label = np.array([int(l) for l in label.split()], dtype=np.int)\n",
    "                x.append(cnt)\n",
    "                y.append(label)\n",
    "        \n",
    "        x_t, y_t, x_ts, y_ts = split_data(x, y)\n",
    "        \n",
    "        for epoch in epochs:\n",
    "            build_model(x_t, y_t, x_ts, y_ts, target, neurons=32, hidden_layers=6, epochs=epoch)\n",
    "            build_model(x_t, y_t, x_ts, y_ts, target, neurons=64, hidden_layers=6, epochs=epoch)\n",
    "            build_model(x_t, y_t, x_ts, y_ts, target, neurons=128, hidden_layers=6, epochs=epoch)\n",
    "\n",
    "\n",
    "\n",
    "        for layer in layers:\n",
    "            for neuron in neurons:\n",
    "                for epoch in epochs:\n",
    "                    build_model(x_t, y_t, x_ts, y_ts, target, neurons=neuron, hidden_layers=layer, epochs=epoch)\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
