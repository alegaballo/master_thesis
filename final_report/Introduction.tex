\chapter{Introduction}

%\section{Overview}
Data-intensive computing requires seamless processing power which is often not available at the network-edge but rather hosted in the cloud platforms. The huge amount of mobile and IoT devices that has become available in the past few years, is able to produce a massive quantity of data, which contributes to the very famous world of big data. The majority of these devices do not have or can not handle the computational requirements to process the data they capture and so leave to the cloud the responsibility to perform the computations. This process of transferring computation tasks to another platform is called {\it computation offloading} and it is crucial to the mobile devices because it results in lower processing time and energy consumption. In critical scenarios, such as natural disasters, not only computation offloading becomes necessary, but latency requirements become more strict, making paths management essential to satisfy these requisites. Current systems for traffic offloading are usually performance unaware (e.g. OSPF, ECMP), achieving therefore sub-optimal performance. Many people have proposed the use of machine learning techniques to solve network problems, including traffic classification~\cite{nguyen2008survey} and latency prediction~\cite{end-to-end}; however, no one has ever used LSTM to train network devices to steer traffic in a virtual network. In this work we develop an architecture to be deployed at the edge of the network to assist the offloading process and make use of machine learning techniques to perform path management. The goal is to outperform the classic routing policies in terms of latency and throughput by learning implicit patterns in network traces.

In particular, in this thesis we make the following contributions:
\begin{itemize}
\item the design of an edge computing architecture for \textbf{offloading} management in edge computing, that describes the macro blocks required for such a system and proposes an offloading protocol
\item a deep learning based \textbf{path prediction system} as part of the offloading architecture; this system is meant to be used as an offloading policy in the proposed architecture 
\item performance evaluation extended to different use cases: we evaluate the prediction system first for its ability to learn from an existing model, second as a routing algorithm replacement.
\end{itemize}
%\section{Structure}
This report is organized as follows:
\paragraph{Chapter~\ref{ch:background}} contains a brief background about machine learning and networking notions and main techniques used in this project.
\paragraph{Chapter~\ref{ch:contribution}} describes the personal contribution of this project, including the details about the architecture and the implementation of the path predictor system.
\paragraph{Chapter~\ref{ch:related_work}} illustrates a summary of the related work.
\paragraph{Chapter~\ref{ch:results}} shows considerations and results of the implemented system.
\paragraph{Chapter~\ref{ch:conclusion}} presents comments about the outcome of the project and possible future developments.

