\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Offloading Architecture}{15}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:contribution}{{4}{15}{Offloading Architecture}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Task Offloading Architecture and~\\Offloading Protocol}{15}{section.4.1}}
\newlabel{sec:task_off}{{4.1}{15}{Task Offloading Architecture and~\\Offloading Protocol}{section.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Offloading Architecture}{15}{subsection.4.1.1}}
\newlabel{sec:architecture}{{4.1.1}{15}{Offloading Architecture}{subsection.4.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Offloading system architecture.}}{16}{figure.4.1}}
\newlabel{fig:offloading_system_arch}{{4.1}{16}{Offloading system architecture}{figure.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Offloading Protocol}{17}{subsection.4.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Offloading workflow: mobile devices and an offloading server orchestrate the request via an SDN controller}}{17}{figure.4.2}}
\newlabel{fig:protocol}{{4.2}{17}{Offloading workflow: mobile devices and an offloading server orchestrate the request via an SDN controller}{figure.4.2}{}}
\citation{cyberforagingsurvey}
\citation{protobuf}
\@writefile{toc}{\contentsline {paragraph}{Abstract Syntax Notation}{18}{section*.15}}
\citation{hendrickson2016serverless}
\citation{fox2017status}
\@writefile{toc}{\contentsline {paragraph}{OffloadRequest}{19}{section*.16}}
\@writefile{toc}{\contentsline {paragraph}{Response}{19}{section*.17}}
\citation{openflow}
\@writefile{toc}{\contentsline {paragraph}{Message}{20}{section*.18}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Path prediction via Deep Learning}{20}{section.4.2}}
\newlabel{sec:path_prediction}{{4.2}{20}{Path prediction via Deep Learning}{section.4.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Why Deep Learning?}{20}{section*.19}}
\citation{caida}
\citation{fb_dataset}
\citation{topo_zoo}
\citation{mininet}
\citation{openflow}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Dataset}{22}{subsection.4.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1.1}Topology}{22}{subsubsection.4.2.1.1}}
\newlabel{sec:net_topology}{{4.2.1.1}{22}{Topology}{subsubsection.4.2.1.1}{}}
\citation{mininext}
\citation{quagga}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Model topology: R1-R6 are outer routers while R7-R10 are inner routers. Each router runs a next-hop predictor based on LSTM.}}{23}{figure.4.3}}
\newlabel{fig:topology}{{4.3}{23}{Model topology: R1-R6 are outer routers while R7-R10 are inner routers. Each router runs a next-hop predictor based on LSTM}{figure.4.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1.2}Routing information}{23}{subsubsection.4.2.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Quagga router implementation in MiniNext.}}{24}{figure.4.4}}
\newlabel{fig:quagga_mininext}{{4.4}{24}{Quagga router implementation in MiniNext}{figure.4.4}{}}
\citation{ryu}
\citation{iperf}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1.3}Router packet counter}{25}{subsubsection.4.2.1.3}}
\newlabel{sec:packet_counter}{{4.2.1.3}{25}{Router packet counter}{subsubsection.4.2.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1.4}Dataset Generation}{25}{subsubsection.4.2.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Router packet counter explanation}}{26}{figure.4.5}}
\newlabel{fig:packet_counter}{{4.5}{26}{Router packet counter explanation}{figure.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Traffic generation algorithm}}{27}{figure.4.6}}
\newlabel{fig:traffic_gen}{{4.6}{27}{Traffic generation algorithm}{figure.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Deep Learning Model}{27}{subsection.4.2.2}}
\newlabel{sec:dl_model}{{4.2.2}{27}{Deep Learning Model}{subsection.4.2.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Dataset generation parameters.}}{27}{table.4.1}}
\newlabel{tab:dataset_params}{{4.1}{27}{Dataset generation parameters}{table.4.1}{}}
\citation{Kato}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Recurrent neural network and its unfolded version.\footnotemark }}{28}{figure.4.7}}
\newlabel{fig:rnn}{{4.7}{28}{Recurrent neural network and its unfolded version.\protect \footnotemark }{figure.4.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2.1}Input/Output modeling}{28}{subsubsection.4.2.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2.2}Neural Network Architecture}{29}{subsubsection.4.2.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Examples of paths connecting the validation target.}}{30}{figure.4.8}}
\newlabel{fig:validation_target}{{4.8}{30}{Examples of paths connecting the validation target}{figure.4.8}{}}
\citation{Goodfellow-et-al-2016}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces LSTM architectures comparison.}}{31}{table.4.2}}
\newlabel{tab:arch_results}{{4.2}{31}{LSTM architectures comparison}{table.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces LSTM architectures average training time.}}{31}{table.4.3}}
\newlabel{tab:arch_timing}{{4.3}{31}{LSTM architectures average training time}{table.4.3}{}}
\citation{srivastava2014dropout}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Comparison between training time and accuracy for 128 neurons. }}{32}{figure.4.9}}
\newlabel{fig:timing_cmp}{{4.9}{32}{Comparison between training time and accuracy for 128 neurons}{figure.4.9}{}}
\newlabel{fn:activation_fun}{{3}{32}{Neural Network Architecture}{figure.4.9}{}}
\citation{ryu}
\citation{protobuf}
\citation{mininet}
\citation{quagga}
\citation{keras}
\citation{tensorflow}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Impact of input normalization on training accuracy and loss.}}{33}{figure.4.10}}
\newlabel{fig:normalization_cmp}{{4.10}{33}{Impact of input normalization on training accuracy and loss}{figure.4.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Implementation}{33}{section.4.3}}
\newlabel{sec:implementation}{{4.3}{33}{Implementation}{section.4.3}{}}
\@setckpt{Contribution}{
\setcounter{page}{34}
\setcounter{equation}{0}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{3}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{3}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{3}
\setcounter{SDpage}{0}
\setcounter{NumberSD}{0}
\setcounter{tomo}{0}
\setcounter{Item}{15}
\setcounter{Hfootnote}{9}
\setcounter{bookmark@seq@number}{25}
\setcounter{float@type}{16}
\setcounter{algorithm}{0}
\setcounter{ALC@unique}{9}
\setcounter{ALC@line}{9}
\setcounter{ALC@rem}{9}
\setcounter{ALC@depth}{0}
\setcounter{ABCIaux}{0}
\setcounter{ABCImax}{0}
\setcounter{lstnumber}{1}
\setcounter{lips@count}{0}
\setcounter{section@level}{1}
\setcounter{lstlisting}{0}
}
